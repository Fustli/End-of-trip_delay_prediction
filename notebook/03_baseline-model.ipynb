{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66b0ec7e",
   "metadata": {},
   "source": [
    "# Baseline Models\n",
    "\n",
    "## STEP 0: Environment setup\n",
    "Import libraries, load config, and initialize a file+stdout logger for a reproducible run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2bbaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Add src/ directory to path for config + logger utils\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "import config\n",
    "from utils import setup_logger\n",
    "\n",
    "logger = setup_logger(\n",
    "    name=\"baseline-model\",\n",
    "    log_dir=getattr(config, \"LOG_DIR\", os.path.join(os.getcwd(), \"log\")),\n",
    "    filename=\"baseline-log.txt\",\n",
    "    level=logging.INFO,\n",
    "    mode=\"w\",\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logger.info(f\"Device: {device}\")\n",
    "logger.info(\"Baseline notebook initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96022c8",
   "metadata": {},
   "source": [
    "## STEP 1: Load and preprocess\n",
    "Load the cleaned dataset and create basic time features used by the baselines (hour/minute/day-of-week)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92b5709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Load Data ---\n",
    "cleaned_path = os.path.join(config.DATA_DIR, \"vehicle_positions_cleaned.csv\")\n",
    "\n",
    "if os.path.exists(cleaned_path):\n",
    "    logger.info(f\"Loading data from: {cleaned_path}\")\n",
    "    df = pd.read_csv(cleaned_path)\n",
    "else:\n",
    "    error_msg = f\"Could not find dataset at {cleaned_path}\"\n",
    "    logger.error(error_msg)\n",
    "    raise FileNotFoundError(error_msg)\n",
    "\n",
    "# --- 2. Feature Engineering (Extracting Time) ---\n",
    "# Ensure timestamp is datetime\n",
    "df['dt'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "# Log the time range of the dataset for context\n",
    "logger.info(f\"Dataset time range: {df['dt'].min()} to {df['dt'].max()}\")\n",
    "\n",
    "# Create numeric features\n",
    "df['hour'] = df['dt'].dt.hour\n",
    "df['minute'] = df['dt'].dt.minute\n",
    "df['day_of_week'] = df['dt'].dt.dayofweek  # Monday=0, Sunday=6\n",
    "\n",
    "# --- 3. Select Features for Linear Regression ---\n",
    "# We use Space (Lat/Lon) and Time (Hour/Min/Day)\n",
    "# Check if config has feature definitions, otherwise default to hardcoded list\n",
    "feature_cols = getattr(config, 'BASELINE_FEATURES', ['latitude', 'longitude', 'hour', 'minute', 'day_of_week'])\n",
    "target_col = getattr(config, 'TARGET_COL', 'delay_seconds')\n",
    "\n",
    "logger.info(f\"Selected Features: {feature_cols}\")\n",
    "logger.info(f\"Target Variable: {target_col}\")\n",
    "\n",
    "# Drop rows with missing values in these specific columns\n",
    "initial_rows = len(df)\n",
    "df_model = df.dropna(subset=feature_cols + [target_col]).copy()\n",
    "dropped_rows = initial_rows - len(df_model)\n",
    "\n",
    "if dropped_rows > 0:\n",
    "    logger.warning(f\"Dropped {dropped_rows} rows due to missing values in feature/target columns.\")\n",
    "else:\n",
    "    logger.info(\"No rows dropped; data is clean.\")\n",
    "\n",
    "logger.info(f\"Data ready for modeling. Final Row Count: {len(df_model):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdfdbf8",
   "metadata": {},
   "source": [
    "## STEP 2: Split and scale\n",
    "Split into train/test and apply `StandardScaler` (fit on train only) to keep the evaluation fair and stable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232f6edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Prepare Data for Splitting ---\n",
    "X = df_model[feature_cols]\n",
    "y = df_model[target_col]\n",
    "\n",
    "# Retrieve split parameters from config or use defaults\n",
    "test_size = getattr(config, 'TEST_SIZE', 0.2)\n",
    "random_state = getattr(config, 'RANDOM_STATE', 42)\n",
    "\n",
    "logger.info(f\"Splitting data with Test Size: {test_size} and Random State: {random_state}\")\n",
    "\n",
    "# --- 2. Split Data ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=test_size,\n",
    "    random_state=random_state,\n",
    "    )\n",
    "\n",
    "logger.info(\"Data split complete.\")\n",
    "logger.info(f\"  - Train: {X_train.shape[0]:,} rows\")\n",
    "logger.info(f\"  - Test:  {X_test.shape[0]:,} rows\")\n",
    "\n",
    "# --- 3. Scale Data (Normalize inputs) ---\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit on TRAIN, transform on BOTH to avoid leakage\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "logger.info(\"Feature scaling complete.\")\n",
    "\n",
    "# Safety check for NaNs after scaling (e.g., if a column had 0 variance)\n",
    "if np.isnan(X_train_scaled).any() or np.isnan(X_test_scaled).any():\n",
    "    logger.error(\"NaNs detected after scaling. Check for constant features.\")\n",
    "else:\n",
    "    logger.info(\"Scaling verification passed: No NaNs detected.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c16bac",
   "metadata": {},
   "source": [
    "## STEP 3: Dummy baseline\n",
    "Establish a minimum bar: always predicting the train mean delay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15dffb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Establishing the 'Dummy' Baseline ---\n",
    "logger.info(\"--- Starting Dummy Baseline Training ---\")\n",
    "\n",
    "# Create a dummy regressor that always predicts the MEAN of the training set\n",
    "dummy_regr = DummyRegressor(strategy=\"mean\")\n",
    "dummy_regr.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_dummy = dummy_regr.predict(X_test_scaled)\n",
    "\n",
    "# Calculate Metrics\n",
    "mae_dummy = mean_absolute_error(y_test, y_pred_dummy)\n",
    "mse_dummy = mean_squared_error(y_test, y_pred_dummy)\n",
    "rmse_dummy = np.sqrt(mse_dummy)\n",
    "r2_dummy = r2_score(y_test, y_pred_dummy)\n",
    "\n",
    "# Log the results clearly\n",
    "logger.info(\"--- DUMMY BASELINE RESULTS ---\")\n",
    "logger.info(f\"Strategy: Always predict global mean ({y_train.mean():.2f} sec)\")\n",
    "logger.info(f\"MAE (Mean Absolute Error):  {mae_dummy:.2f} seconds\")\n",
    "logger.info(f\"RMSE (Root Mean Sq Error):  {rmse_dummy:.2f} seconds\")\n",
    "logger.info(f\"R2 Score (Variance expl.):  {r2_dummy:.4f}\") \n",
    "\n",
    "# Store baseline MAE in config or a variable for easy comparison later\n",
    "baseline_mae = mae_dummy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cfea83",
   "metadata": {},
   "source": [
    "## STEP 4: Linear regression\n",
    "Train a simple linear model on (lat, lon, time) features and compare against the dummy baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c01204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. Training Linear Regression ---\n",
    "logger.info(\"--- Starting Linear Regression Training ---\")\n",
    "\n",
    "# 1. Initialize and Train\n",
    "# Optional: Load hyperparameters from config if they exist (e.g., fit_intercept)\n",
    "fit_intercept = getattr(config, 'LIN_REG_FIT_INTERCEPT', True)\n",
    "lin_reg = LinearRegression(fit_intercept=fit_intercept)\n",
    "\n",
    "lin_reg.fit(X_train_scaled, y_train)\n",
    "logger.info(\"Model training complete.\")\n",
    "\n",
    "# 2. Predict on Test Set\n",
    "y_pred_lin = lin_reg.predict(X_test_scaled)\n",
    "\n",
    "# 3. Evaluate\n",
    "mae_lin = mean_absolute_error(y_test, y_pred_lin)\n",
    "mse_lin = mean_squared_error(y_test, y_pred_lin)\n",
    "rmse_lin = np.sqrt(mse_lin)\n",
    "r2_lin = r2_score(y_test, y_pred_lin)\n",
    "\n",
    "logger.info(\"--- LINEAR REGRESSION RESULTS ---\")\n",
    "logger.info(f\"MAE (Mean Absolute Error): {mae_lin:.2f} seconds\")\n",
    "logger.info(f\"RMSE (Root Mean Sq Error): {rmse_lin:.2f} seconds\")\n",
    "logger.info(f\"R² Score:                  {r2_lin:.4f}\")\n",
    "\n",
    "# 4. Compare with Baseline\n",
    "improvement = mae_dummy - mae_lin\n",
    "logger.info(f\"Improvement over Dummy:    {improvement:.2f} seconds\")\n",
    "\n",
    "if improvement > 0:\n",
    "    logger.info(\"RESULT: The model SUCCESSFULY beat the baseline.\")\n",
    "else:\n",
    "    logger.warning(\"RESULT: The model FAILED to beat the baseline. Features may be non-predictive.\")\n",
    "\n",
    "# 5. Inspect Coefficients (Feature Importance)\n",
    "# This shows us which features the linear model thinks are most important\n",
    "logger.info(\"--- Learned Coefficients (Weights) ---\")\n",
    "for feature_name, coef in zip(feature_cols, lin_reg.coef_):\n",
    "    logger.info(f\"  {feature_name}: {coef:.4f}\")\n",
    "logger.info(f\"  Intercept: {lin_reg.intercept_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deee2b05",
   "metadata": {},
   "source": [
    "## STEP 5: Diagnostics (linear regression)\n",
    "Plot coefficients, actual vs predicted, and residual distribution; save the figure under `plots/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d65152b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6. Visualization: Linear Regression Diagnostics ---\n",
    "logger.info(\"--- Generating Linear Regression Visualizations ---\")\n",
    "\n",
    "plots_dir = os.path.abspath(getattr(config, 'PLOTS_DIR', os.path.join(os.getcwd(), 'plots')))\n",
    "os.makedirs(plots_dir, exist_ok=True)\n",
    "\n",
    "plt.figure(figsize=(20, 6))\n",
    "\n",
    "# --- A. COEFFICIENTS ---\n",
    "plt.subplot(1, 3, 1)\n",
    "\n",
    "coeffs = pd.DataFrame({\n",
    "    'Feature': feature_cols,\n",
    "    'Weight (Coefficient)': lin_reg.coef_,\n",
    "})\n",
    "coeffs['Abs_Weight'] = coeffs['Weight (Coefficient)'].abs()\n",
    "coeffs = coeffs.sort_values(by='Abs_Weight', ascending=False)\n",
    "\n",
    "sns.barplot(\n",
    "    x='Weight (Coefficient)',\n",
    "    y='Feature',\n",
    "    hue='Feature',\n",
    "    data=coeffs,\n",
    "    palette='coolwarm',\n",
    "    legend=False,\n",
    " )\n",
    "plt.title('Linear Regression: Feature Coefficients', fontsize=16)\n",
    "plt.xlabel('Weight (Impact on Delay)')\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# --- B. ACTUAL VS PREDICTED ---\n",
    "plt.subplot(1, 3, 2)\n",
    "\n",
    "if len(y_test) > 500:\n",
    "    rng = np.random.RandomState(getattr(config, 'RANDOM_STATE', 42))\n",
    "    indices = rng.choice(len(y_test), 500, replace=False)\n",
    "    y_test_sample = y_test.iloc[indices]\n",
    "    y_pred_sample = y_pred_lin[indices]\n",
    "    logger.info(\"Subsampled 500 points for clearer scatter plot.\")\n",
    "else:\n",
    "    y_test_sample = y_test\n",
    "    y_pred_sample = y_pred_lin\n",
    "\n",
    "sns.scatterplot(x=y_test_sample, y=y_pred_sample, alpha=0.6, color='blue', label='Predictions')\n",
    "\n",
    "axis_min = min(y_test_sample.min(), y_pred_sample.min())\n",
    "axis_max = max(y_test_sample.max(), y_pred_sample.max())\n",
    "plt.plot([axis_min, axis_max], [axis_min, axis_max], 'r--', linewidth=2, label='Perfect Prediction')\n",
    "\n",
    "plt.xlabel('Actual Delay (seconds)')\n",
    "plt.ylabel('Predicted Delay (seconds)')\n",
    "plt.title(f'Actual vs Predicted (MAE: {mae_lin:.0f}s)', fontsize=16)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# --- C. RESIDUAL DISTRIBUTION ---\n",
    "plt.subplot(1, 3, 3)\n",
    "residuals = y_test - y_pred_lin\n",
    "\n",
    "sns.histplot(residuals, bins=50, kde=True, color='green', line_kws={'linewidth': 2})\n",
    "plt.axvline(0, color='red', linestyle='--')\n",
    "plt.title('Distribution of Errors (Residuals)', fontsize=16)\n",
    "plt.xlabel('Error (Seconds)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlim(-500, 500)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plot_path = os.path.join(plots_dir, 'baseline_linear_regression_diagnostics.png')\n",
    "plt.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
    "logger.info(f\"Saved plot: {plot_path}\")\n",
    "plt.show()\n",
    "\n",
    "logger.info(\"Top coefficients (by absolute weight):\")\n",
    "for _, row in coeffs.iterrows():\n",
    "    logger.info(f\"  {row['Feature']}: {row['Weight (Coefficient)']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079abe7f",
   "metadata": {},
   "source": [
    "## STEP 6: Random Forest baseline\n",
    "Train a non-linear baseline and evaluate on the held-out test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db0d7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6. Non-Linear Baseline (Random Forest) ---\n",
    "logger.info(\"--- Starting Random Forest Training ---\")\n",
    "\n",
    "# 1. Initialize Random Forest\n",
    "# We pull parameters from config if available, otherwise default to the baseline settings\n",
    "n_estimators = getattr(config, 'RF_N_ESTIMATORS', 50)\n",
    "max_depth = getattr(config, 'RF_MAX_DEPTH', 10)\n",
    "random_state = getattr(config, 'RANDOM_STATE', 42)\n",
    "\n",
    "logger.info(f\"Training Random Forest (n_estimators={n_estimators}, max_depth={max_depth})...\")\n",
    "\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=n_estimators,\n",
    "    max_depth=max_depth,\n",
    "    random_state=random_state,\n",
    "    n_jobs=-1  # Use all available CPU cores\n",
    ")\n",
    "\n",
    "# 2. Train\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "logger.info(\"Random Forest training complete.\")\n",
    "\n",
    "# 3. Predict\n",
    "y_pred_rf = rf_model.predict(X_test_scaled)\n",
    "\n",
    "# 4. Evaluate\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf) # Added for full context\n",
    "rmse_rf = np.sqrt(mse_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "logger.info(\"--- RANDOM FOREST RESULTS ---\")\n",
    "logger.info(f\"MAE (Mean Absolute Error): {mae_rf:.2f} seconds\")\n",
    "logger.info(f\"RMSE (Root Mean Sq Error): {rmse_rf:.2f} seconds\")\n",
    "logger.info(f\"R² Score:                  {r2_rf:.4f}\")\n",
    "\n",
    "# Calculate Improvement over Dummy\n",
    "improvement_rf = mae_dummy - mae_rf\n",
    "logger.info(f\"Improvement over Dummy:    {improvement_rf:.2f} seconds\")\n",
    "\n",
    "# Optional: Compare vs Linear if available\n",
    "if 'mae_lin' in locals():\n",
    "    improvement_lin = mae_lin - mae_rf\n",
    "    logger.info(f\"Improvement over Linear:   {improvement_lin:.2f} seconds\")\n",
    "\n",
    "if improvement_rf > 0:\n",
    "    logger.info(\"RESULT: Random Forest SUCCESSFULY beat the baseline.\")\n",
    "else:\n",
    "    logger.warning(\"RESULT: Random Forest FAILED to beat the baseline.\")\n",
    "\n",
    "# 5. Feature Importance\n",
    "# See which features actually matter the most\n",
    "importances = pd.DataFrame({\n",
    "    'Feature': feature_cols,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "logger.info(\"\\n--- What actually drives delay? (Feature Importance) ---\")\n",
    "for index, row in importances.iterrows():\n",
    "    logger.info(f\"Feature: {row['Feature']:<15} | Importance: {row['Importance']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634fb7d8",
   "metadata": {},
   "source": [
    "## STEP 7: Diagnostics (Random Forest)\n",
    "Save a diagnostics figure under `plots/` to validate fit and residual behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa22c1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 7. Visualization: Random Forest Diagnostics ---\n",
    "logger.info(\"--- Generating Random Forest Diagnostics ---\")\n",
    "\n",
    "plots_dir = os.path.abspath(getattr(config, 'PLOTS_DIR', os.path.join(os.getcwd(), 'plots')))\n",
    "os.makedirs(plots_dir, exist_ok=True)\n",
    "\n",
    "plt.figure(figsize=(20, 6))\n",
    "\n",
    "# --- A. FEATURE IMPORTANCE ---\n",
    "plt.subplot(1, 3, 1)\n",
    "\n",
    "feat_imp = pd.DataFrame({\n",
    "    'Feature': feature_cols,\n",
    "    'Importance': rf_model.feature_importances_,\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "sns.barplot(\n",
    "    x='Importance',\n",
    "    y='Feature',\n",
    "    hue='Feature',\n",
    "    data=feat_imp,\n",
    "    palette='viridis',\n",
    "    legend=False,\n",
    " )\n",
    "plt.title('Random Forest: Feature Importance', fontsize=16)\n",
    "plt.xlabel('Importance Score')\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# --- B. ACTUAL VS PREDICTED ---\n",
    "plt.subplot(1, 3, 2)\n",
    "\n",
    "if len(y_test) > 1000:\n",
    "    rng = np.random.RandomState(getattr(config, 'RANDOM_STATE', 42))\n",
    "    indices = rng.choice(len(y_test), 1000, replace=False)\n",
    "    y_sample = y_test.iloc[indices]\n",
    "    pred_sample = y_pred_rf[indices]\n",
    "    logger.info(\"Subsampled 1,000 points for scatter plot clarity.\")\n",
    "else:\n",
    "    y_sample = y_test\n",
    "    pred_sample = y_pred_rf\n",
    "\n",
    "sns.scatterplot(x=y_sample, y=pred_sample, alpha=0.5, color='royalblue', s=40)\n",
    "\n",
    "axis_min = min(y_sample.min(), pred_sample.min())\n",
    "axis_max = max(y_sample.max(), pred_sample.max())\n",
    "plt.plot([axis_min, axis_max], [axis_min, axis_max], 'r--', linewidth=2, label='Perfect Prediction')\n",
    "\n",
    "plt.title('Actual vs. Predicted Delays', fontsize=16)\n",
    "plt.xlabel('Actual Delay (s)')\n",
    "plt.ylabel('Predicted Delay (s)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# --- C. RESIDUAL DISTRIBUTION ---\n",
    "plt.subplot(1, 3, 3)\n",
    "residuals = y_test - y_pred_rf\n",
    "\n",
    "sns.histplot(residuals, bins=50, kde=True, color='purple', line_kws={'linewidth': 2})\n",
    "plt.axvline(0, color='red', linestyle='--')\n",
    "plt.title('Distribution of Prediction Errors (Residuals)', fontsize=16)\n",
    "plt.xlabel('Error (Seconds)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlim(-500, 500)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "diag_plot_path = os.path.join(plots_dir, 'baseline_rf_diagnostics.png')\n",
    "plt.savefig(diag_plot_path, dpi=150, bbox_inches='tight')\n",
    "logger.info(f\"Saved plot: {diag_plot_path}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9d203d",
   "metadata": {},
   "source": [
    "## STEP 8: Stop history feature (target encoding)\n",
    "Add `stop_history_mean` computed on the train split (then mapped to test) to avoid leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049a1330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 8. Advanced Feature Engineering (Target Encoding) ---\n",
    "logger.info(\"--- Starting Advanced Feature Engineering (Target Encoding) ---\")\n",
    "\n",
    "# Check if 'last_stop_id' exists in the original dataframe (df is from Step 2)\n",
    "if 'last_stop_id' not in df.columns:\n",
    "    error_msg = \"Column 'last_stop_id' missing from dataframe. Cannot perform target encoding.\"\n",
    "    logger.error(error_msg)\n",
    "    raise ValueError(error_msg)\n",
    "\n",
    "# 1. Create the 'Memory' (Calculate mean delay per stop on TRAIN set)\n",
    "# We strictly use X_train/y_train to avoid \"Data Leakage\" (cheating)\n",
    "train_df_temp = X_train.copy()\n",
    "train_df_temp['target'] = y_train\n",
    "\n",
    "# Retrieve the ID from the original dataframe using the matching indices\n",
    "train_df_temp['last_stop_id'] = df.loc[X_train.index, 'last_stop_id']\n",
    "\n",
    "# Calculate average delay for each specific stop\n",
    "stop_history = train_df_temp.groupby('last_stop_id')['target'].mean()\n",
    "global_mean_delay = y_train.mean()\n",
    "\n",
    "logger.info(f\"Learned historical delays for {len(stop_history)} unique stops.\")\n",
    "logger.info(f\"Global mean delay (fallback for new stops): {global_mean_delay:.2f} seconds\")\n",
    "\n",
    "# 2. Map this 'Memory' to the Features\n",
    "def add_history_feature(X_data, original_df, mapping, global_mean):\n",
    "    \"\"\"\n",
    "    Look up the stop ID for each row in X_data, find its historical average delay,\n",
    "    and fill with global_mean if the stop was never seen during training.\n",
    "    \"\"\"\n",
    "    # Get IDs corresponding to the split (Train or Test)\n",
    "    ids = original_df.loc[X_data.index, 'last_stop_id']\n",
    "    \n",
    "    # Map and fill NaNs (Handling unknown stops in test set)\n",
    "    return ids.map(mapping).fillna(global_mean).values.reshape(-1, 1)\n",
    "\n",
    "# Add the new feature to Train and Test arrays\n",
    "# Note: X_train_scaled is a numpy array, so we use np.hstack to append the new column\n",
    "X_train_history = np.hstack([\n",
    "    X_train_scaled, \n",
    "    add_history_feature(X_train, df, stop_history, global_mean_delay)\n",
    "])\n",
    "\n",
    "X_test_history = np.hstack([\n",
    "    X_test_scaled, \n",
    "    add_history_feature(X_test, df, stop_history, global_mean_delay)\n",
    "])\n",
    "\n",
    "logger.info(f\"Feature Engineering Complete. Feature count increased: {X_train_scaled.shape[1]} -> {X_train_history.shape[1]}\")\n",
    "\n",
    "# 3. Retrain Random Forest with the new 'Smart' feature\n",
    "# We use slightly deeper trees (max_depth=12) as suggested in your snippet to leverage the new info\n",
    "n_estimators = getattr(config, 'RF_N_ESTIMATORS', 50)\n",
    "max_depth_smart = getattr(config, 'RF_SMART_MAX_DEPTH', 12)\n",
    "random_state = getattr(config, 'RANDOM_STATE', 42)\n",
    "\n",
    "logger.info(f\"Training Enhanced Random Forest (Max Depth: {max_depth_smart})...\")\n",
    "\n",
    "rf_smart = RandomForestRegressor(\n",
    "    n_estimators=n_estimators, \n",
    "    max_depth=max_depth_smart, \n",
    "    random_state=random_state, \n",
    "    n_jobs=-1\n",
    ")\n",
    "rf_smart.fit(X_train_history, y_train)\n",
    "logger.info(\"Enhanced Random Forest training complete.\")\n",
    "\n",
    "# 4. Predict & Evaluate\n",
    "y_pred_smart = rf_smart.predict(X_test_history)\n",
    "\n",
    "mae_smart = mean_absolute_error(y_test, y_pred_smart)\n",
    "mse_smart = mean_squared_error(y_test, y_pred_smart)\n",
    "rmse_smart = np.sqrt(mse_smart)\n",
    "r2_smart = r2_score(y_test, y_pred_smart)\n",
    "\n",
    "logger.info(\"--- ENHANCED BASELINE RESULTS (with Stop History) ---\")\n",
    "logger.info(f\"MAE (Mean Absolute Error): {mae_smart:.2f} seconds\")\n",
    "logger.info(f\"RMSE (Root Mean Sq Error): {rmse_smart:.2f} seconds\")\n",
    "logger.info(f\"R² Score:                  {r2_smart:.4f}\")\n",
    "\n",
    "# Compare with previous Standard Random Forest\n",
    "improvement_smart = mae_rf - mae_smart\n",
    "logger.info(f\"Improvement over Standard RF: {improvement_smart:.2f} seconds\")\n",
    "\n",
    "if improvement_smart > 0:\n",
    "    logger.info(\"SUCCESS: Target Encoding (Stop History) improved model performance.\")\n",
    "else:\n",
    "    logger.warning(\"No improvement detected. The historical average might not be predictive.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413fa985",
   "metadata": {},
   "source": [
    "## STEP 9: Enhanced Random Forest diagnostics\n",
    "Visualize the effect of stop history and compare MAE across baseline variants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600685f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 9. Visualizing the Enhanced Baseline & Model Comparison ---\n",
    "logger.info(\"--- Generating Enhanced Model Visualizations ---\")\n",
    "\n",
    "plots_dir = os.path.abspath(getattr(config, 'PLOTS_DIR', os.path.join(os.getcwd(), 'plots')))\n",
    "os.makedirs(plots_dir, exist_ok=True)\n",
    "\n",
    "plt.figure(figsize=(20, 12))\n",
    "\n",
    "# --- A. NEW FEATURE IMPORTANCE ---\n",
    "plt.subplot(2, 2, 1)\n",
    "\n",
    "feature_names_enhanced = feature_cols + ['stop_history_mean']\n",
    "\n",
    "feat_imp_smart = pd.DataFrame({\n",
    "    'Feature': feature_names_enhanced,\n",
    "    'Importance': rf_smart.feature_importances_,\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "sns.barplot(\n",
    "    x='Importance',\n",
    "    y='Feature',\n",
    "    hue='Feature',\n",
    "    data=feat_imp_smart,\n",
    "    palette='magma',\n",
    "    legend=False,\n",
    " )\n",
    "plt.title('Enhanced RF: Feature Importance', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Importance Score')\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# --- B. ACTUAL VS PREDICTED ---\n",
    "plt.subplot(2, 2, 2)\n",
    "\n",
    "if len(y_test) > 1000:\n",
    "    rng = np.random.RandomState(getattr(config, 'RANDOM_STATE', 42))\n",
    "    indices = rng.choice(len(y_test), 1000, replace=False)\n",
    "    y_sample = y_test.iloc[indices]\n",
    "    pred_sample = y_pred_smart[indices]\n",
    "    logger.info(\"Subsampled 1,000 points for Enhanced Scatter Plot.\")\n",
    "else:\n",
    "    y_sample = y_test\n",
    "    pred_sample = y_pred_smart\n",
    "\n",
    "sns.scatterplot(x=y_sample, y=pred_sample, alpha=0.5, color='forestgreen', s=40)\n",
    "\n",
    "axis_min = min(y_sample.min(), pred_sample.min())\n",
    "axis_max = max(y_sample.max(), pred_sample.max())\n",
    "plt.plot([axis_min, axis_max], [axis_min, axis_max], 'r--', linewidth=2, label='Perfect Prediction')\n",
    "\n",
    "plt.title(f'Enhanced Model: Actual vs Predicted (MAE: {mae_smart:.0f}s)', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Actual Delay (s)')\n",
    "plt.ylabel('Predicted Delay (s)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# --- C. MODEL COMPARISON (MAE) ---\n",
    "plt.subplot(2, 1, 2)\n",
    "\n",
    "progress_df = pd.DataFrame({\n",
    "    'Model': ['Dummy', 'Linear Regression', 'Basic RF', 'Enhanced RF'],\n",
    "    'MAE': [mae_dummy, mae_lin, mae_rf, mae_smart],\n",
    "}).sort_values(by='MAE')\n",
    "\n",
    "sns.barplot(x='MAE', y='Model', hue='Model', data=progress_df, palette='coolwarm', legend=False)\n",
    "plt.title('Baseline Comparison (Lower MAE is Better)', fontsize=18, fontweight='bold')\n",
    "plt.xlabel('Mean Absolute Error (seconds)')\n",
    "plt.ylabel('Model')\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "comp_plot_path = os.path.join(plots_dir, 'baseline_enhanced_rf_comparison_dashboard.png')\n",
    "plt.savefig(comp_plot_path, dpi=150, bbox_inches='tight')\n",
    "logger.info(f\"Saved plot: {comp_plot_path}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8597d255",
   "metadata": {},
   "source": [
    "## STEP 10: Lag feature\n",
    "Add `prev_stop_delay` (delay at previous stop) to provide real-time context for the final baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ceb7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 10. Temporal Context (Lag Features) ---\n",
    "logger.info(\"--- Starting Temporal Context Engineering (Lag Features) ---\")\n",
    "\n",
    "# 1. Sort to ensure correct order\n",
    "# We need to process the WHOLE dataframe to ensure we have the sequence for every trip\n",
    "logger.info(\"Sorting dataframe by Trip ID and Timestamp...\")\n",
    "df_sorted = df.sort_values(by=['trip_id', 'timestamp']).copy()\n",
    "\n",
    "# 2. Shift the delay by 1 to get \"Previous Delay\"\n",
    "# We group by trip_id so we don't accidentally shift delay from Trip A to Trip B\n",
    "logger.info(\"Calculating previous stop delays...\")\n",
    "df_sorted['prev_stop_delay'] = df_sorted.groupby('trip_id')['delay_seconds'].shift(1)\n",
    "\n",
    "# 3. Handle NaNs (The first stop of every trip has no \"previous\" delay)\n",
    "# We fill with 0 (assuming trips start on time)\n",
    "# You could also fill with global mean, but 0 is logically sound for \"start of trip\"\n",
    "df_sorted['prev_stop_delay'] = df_sorted['prev_stop_delay'].fillna(0)\n",
    "\n",
    "# 4. Re-merge with our Training/Testing splits\n",
    "# Since we split randomly earlier, we use the original index to map values back correctly\n",
    "# Note: We must ensure indices align perfectly\n",
    "logger.info(\"Mapping lag features back to training/testing sets...\")\n",
    "X_train_lag = df_sorted.loc[X_train.index, 'prev_stop_delay'].values.reshape(-1, 1)\n",
    "X_test_lag  = df_sorted.loc[X_test.index,  'prev_stop_delay'].values.reshape(-1, 1)\n",
    "\n",
    "# 5. Stack it onto our existing \"History\" features\n",
    "# Current Stack: [Scaled Features] + [Stop History] + [Prev Delay]\n",
    "X_train_final = np.hstack([X_train_history, X_train_lag])\n",
    "X_test_final  = np.hstack([X_test_history,  X_test_lag])\n",
    "\n",
    "logger.info(f\"Feature Engineering Complete. Final feature count: {X_train_final.shape[1]}\")\n",
    "\n",
    "# 6. Train Final Random Forest\n",
    "n_estimators = getattr(config, 'RF_N_ESTIMATORS', 50)\n",
    "max_depth_final = getattr(config, 'RF_FINAL_MAX_DEPTH', 12) # Maybe deeper for more features?\n",
    "random_state = getattr(config, 'RANDOM_STATE', 42)\n",
    "\n",
    "logger.info(f\"Training Final 'Context-Aware' Random Forest (Max Depth: {max_depth_final})...\")\n",
    "\n",
    "rf_final = RandomForestRegressor(\n",
    "    n_estimators=n_estimators, \n",
    "    max_depth=max_depth_final, \n",
    "    random_state=random_state, \n",
    "    n_jobs=-1\n",
    ")\n",
    "rf_final.fit(X_train_final, y_train)\n",
    "logger.info(\"Final Random Forest training complete.\")\n",
    "\n",
    "# 7. Evaluate\n",
    "y_pred_final = rf_final.predict(X_test_final)\n",
    "\n",
    "mae_final = mean_absolute_error(y_test, y_pred_final)\n",
    "mse_final = mean_squared_error(y_test, y_pred_final)\n",
    "rmse_final = np.sqrt(mse_final)\n",
    "r2_final = r2_score(y_test, y_pred_final)\n",
    "\n",
    "logger.info(\"--- FINAL CONTEXT-AWARE MODEL RESULTS ---\")\n",
    "logger.info(f\"MAE (Mean Absolute Error): {mae_final:.2f} seconds\")\n",
    "logger.info(f\"RMSE (Root Mean Sq Error): {rmse_final:.2f} seconds\")\n",
    "logger.info(f\"R² Score:                  {r2_final:.4f}\")\n",
    "\n",
    "# Compare with previous \"History\" Model\n",
    "improvement_final = mae_smart - mae_final\n",
    "logger.info(f\"Improvement over History Model: {improvement_final:.2f} seconds\")\n",
    "\n",
    "if improvement_final > 0:\n",
    "    logger.info(\"SUCCESS: Adding real-time lag features improved accuracy.\")\n",
    "else:\n",
    "    logger.warning(\"No improvement from lag features. Check if 'prev_stop_delay' has valid data.\")\n",
    "\n",
    "# --- Save Final Metrics to Config/File for later comparison with GNN ---\n",
    "final_metrics = {\n",
    "    \"MAE\": mae_final,\n",
    "    \"RMSE\": rmse_final,\n",
    "    \"R2\": r2_final\n",
    "}\n",
    "logger.info(f\"Final Baselines Established: {final_metrics}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2e836d",
   "metadata": {},
   "source": [
    "## STEP 11: Final baseline dashboard\n",
    "Generate a single dashboard (feature importance, scatter, residuals, leaderboard) and save it under `plots/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0c849c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 11. Final Visualization & Leaderboard ---\n",
    "logger.info(\"--- Generating Final Model Dashboard ---\")\n",
    "\n",
    "plots_dir = os.path.abspath(getattr(config, 'PLOTS_DIR', os.path.join(os.getcwd(), 'plots')))\n",
    "os.makedirs(plots_dir, exist_ok=True)\n",
    "\n",
    "plt.figure(figsize=(20, 14))\n",
    "\n",
    "# --- A. FEATURE IMPORTANCE ---\n",
    "plt.subplot(2, 2, 1)\n",
    "\n",
    "final_feature_names = feature_cols + ['stop_history_mean', 'prev_stop_delay']\n",
    "\n",
    "feat_imp_final = pd.DataFrame({\n",
    "    'Feature': final_feature_names,\n",
    "    'Importance': rf_final.feature_importances_,\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "sns.barplot(\n",
    "    x='Importance',\n",
    "    y='Feature',\n",
    "    hue='Feature',\n",
    "    data=feat_imp_final,\n",
    "    palette='rocket',\n",
    "    legend=False,\n",
    " )\n",
    "plt.title('Final Model: Feature Importance', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Importance Score')\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# --- B. ACTUAL VS PREDICTED ---\n",
    "plt.subplot(2, 2, 2)\n",
    "\n",
    "if len(y_test) > 1000:\n",
    "    rng = np.random.RandomState(getattr(config, 'RANDOM_STATE', 42))\n",
    "    indices = rng.choice(len(y_test), 1000, replace=False)\n",
    "    y_sample = y_test.iloc[indices]\n",
    "    pred_sample = y_pred_final[indices]\n",
    "    logger.info(\"Subsampled 1,000 points for Final Scatter Plot.\")\n",
    "else:\n",
    "    y_sample = y_test\n",
    "    pred_sample = y_pred_final\n",
    "\n",
    "sns.scatterplot(x=y_sample, y=pred_sample, alpha=0.6, color='darkorange', s=40)\n",
    "\n",
    "axis_min = min(y_sample.min(), pred_sample.min())\n",
    "axis_max = max(y_sample.max(), pred_sample.max())\n",
    "plt.plot([axis_min, axis_max], [axis_min, axis_max], 'k--', linewidth=3, label='Perfect Prediction')\n",
    "\n",
    "plt.title(f'Actual vs. Predicted (R²: {r2_final:.2f})', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Actual Delay (s)')\n",
    "plt.ylabel('Predicted Delay (s)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# --- C. RESIDUAL DISTRIBUTION ---\n",
    "plt.subplot(2, 2, 3)\n",
    "residuals_final = y_test - y_pred_final\n",
    "sns.histplot(residuals_final, bins=50, kde=True, color='teal', line_kws={'linewidth': 2})\n",
    "plt.axvline(0, color='black', linestyle='--')\n",
    "plt.title('Final Model Residual Distribution', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Error (Seconds)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlim(-500, 500)\n",
    "\n",
    "# --- D. LEADERBOARD ---\n",
    "plt.subplot(2, 2, 4)\n",
    "leaderboard_df = pd.DataFrame({\n",
    "    'Model': ['Dummy', 'Linear', 'Basic RF', 'Enhanced RF', 'Final RF'],\n",
    "    'MAE': [mae_dummy, mae_lin, mae_rf, mae_smart, mae_final],\n",
    "}).sort_values(by='MAE')\n",
    "sns.barplot(x='MAE', y='Model', hue='Model', data=leaderboard_df, palette='Spectral', legend=False)\n",
    "plt.title('Leaderboard (Lower MAE is Better)', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Mean Absolute Error (seconds)')\n",
    "plt.ylabel('Model')\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "dashboard_path = os.path.join(plots_dir, 'baseline_final_dashboard.png')\n",
    "plt.savefig(dashboard_path, dpi=150, bbox_inches='tight')\n",
    "logger.info(f\"Saved plot: {dashboard_path}\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
