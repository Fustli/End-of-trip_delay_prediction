{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b62f2b88",
   "metadata": {},
   "source": [
    "# GNN Model V2 (Context-aware GAT)\n",
    "\n",
    "## STEP 0: Environment setup\n",
    "Initialize libraries, load config, and set up logging for a reproducible V2 training run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3870e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# GNN Imports\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GATConv\n",
    "\n",
    "# Utils\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Add src/ directory to path for config + logger utils\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "import config\n",
    "from utils import setup_logger\n",
    "\n",
    "logger = setup_logger(\n",
    "    name=\"gnn-model-v2\",\n",
    "    log_dir=getattr(config, 'LOG_DIR', 'log'),\n",
    "    filename=\"gnn_model_v2_training.log\",\n",
    "    level=logging.INFO,\n",
    "    mode=\"w\",\n",
    ")\n",
    "\n",
    "logger.info(\"--- STARTING GNN MODEL V2 TRAINING ---\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "logger.info(f\"Device: {device}\")\n",
    "\n",
    "# --- 1. Load Data ---\n",
    "clean_path = getattr(config, 'CLEANED_CSV_PATH', os.path.join(config.DATA_DIR, \"vehicle_positions_cleaned.csv\"))\n",
    "logger.info(f\"Loading data from: {clean_path}\")\n",
    "df = pd.read_csv(clean_path)\n",
    "\n",
    "# Sort strictly for lag/sequence calculation\n",
    "df['dt'] = pd.to_datetime(df['timestamp'])\n",
    "df = df.sort_values(['trip_id', 'dt']).reset_index(drop=True)\n",
    "logger.info(f\"Loaded rows: {len(df):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54d4766",
   "metadata": {},
   "source": [
    "## STEP 1: Feature engineering (context features)\n",
    "Add real-time context features so the GNN can learn more than static stop popularity.\n",
    "\n",
    "- `prev_stop_delay`: previous-stop delay within each `trip_id`\n",
    "- Cyclical time: `hour_sin/cos`, `day_sin/cos`\n",
    "- Trajectory context: `stop_sequence` within each trip\n",
    "- Stop history: `history_mean` (target encoding)\n",
    "- Scaling: separate scalers for node features vs. dynamic context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c27b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STEP 2: FEATURE ENGINEERING (V2 UPGRADES)\n",
    "# =============================================================================\n",
    "logger.info(\"--- Generating Advanced Features ---\")\n",
    "\n",
    "# 1. Real-Time Lag (Previous Stop Delay)\n",
    "# Shift delay by 1 within each trip\n",
    "df['prev_stop_delay'] = df.groupby('trip_id')['delay_seconds'].shift(1).fillna(0)\n",
    "\n",
    "# 2. Cyclical Time Embeddings\n",
    "df['hour'] = df['dt'].dt.hour\n",
    "df['day_of_week'] = df['dt'].dt.dayofweek\n",
    "\n",
    "df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)\n",
    "df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)\n",
    "df['day_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7)\n",
    "df['day_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7)\n",
    "\n",
    "# 3. [NEW] Stop Sequence (Trajectory Context)\n",
    "# Counts 0, 1, 2... for every stop in the trip.\n",
    "# Helps model know if it's the start or end of a route.\n",
    "logger.info(\"Generating 'Stop Sequence' feature...\")\n",
    "df['stop_sequence'] = df.groupby('trip_id').cumcount()\n",
    "\n",
    "# 4. Target Encoding (History)\n",
    "stop_col = 'last_stop_id' if 'last_stop_id' in df.columns else 'stop_id'\n",
    "global_mean = df['delay_seconds'].mean()\n",
    "stop_history = df.groupby(stop_col)['delay_seconds'].mean()\n",
    "df['history_mean'] = df[stop_col].map(stop_history).fillna(global_mean)\n",
    "\n",
    "# --- SCALING ---\n",
    "logger.info(\"Scaling Features...\")\n",
    "\n",
    "# A. Node Features (Static)\n",
    "scaler_nodes = StandardScaler()\n",
    "df[['lat_scaled', 'lon_scaled', 'hist_scaled']] = scaler_nodes.fit_transform(\n",
    "    df[['latitude', 'longitude', 'history_mean']]\n",
    ")\n",
    "\n",
    "# B. Context Features (Dynamic)\n",
    "# Clip lag to -30min to +60min to prevent extreme outliers from killing the gradients\n",
    "df['prev_delay_clipped'] = df['prev_stop_delay'].clip(-1800, 3600)\n",
    "scaler_lag = StandardScaler()\n",
    "df['prev_delay_scaled'] = scaler_lag.fit_transform(df[['prev_delay_clipped']])\n",
    "\n",
    "# Scale Sequence\n",
    "scaler_seq = StandardScaler()\n",
    "df['seq_scaled'] = scaler_seq.fit_transform(df[['stop_sequence']])\n",
    "\n",
    "logger.info(\"Feature Engineering Complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91acb4b5",
   "metadata": {},
   "source": [
    "## STEP 2: Graph construction (static city map)\n",
    "Build a directed stop graph once and keep it on the GPU.\n",
    "\n",
    "- Nodes: unique stops (`stop_idx`) with static features (`lat_scaled`, `lon_scaled`, `hist_scaled`)\n",
    "- Edges: observed stop-to-stop transitions within each trip (A → B)\n",
    "- Output: `torch_geometric.data.Data(x, edge_index)` used by every batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3274a3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STEP 3: GRAPH CONSTRUCTION\n",
    "# =============================================================================\n",
    "logger.info(\"--- Constructing Transit Graph ---\")\n",
    "\n",
    "stop_encoder = LabelEncoder()\n",
    "df['stop_idx'] = stop_encoder.fit_transform(df[stop_col])\n",
    "\n",
    "# Node Features Tensor\n",
    "node_cols = ['lat_scaled', 'lon_scaled', 'hist_scaled']\n",
    "node_features_df = df.groupby('stop_idx')[node_cols].mean()\n",
    "x = torch.tensor(node_features_df.values, dtype=torch.float)\n",
    "\n",
    "# Edge Index\n",
    "df_sorted = df.sort_values(by=['trip_id', 'dt'])\n",
    "df_sorted['next_stop_idx'] = df_sorted.groupby('trip_id')['stop_idx'].shift(-1)\n",
    "edges_df = df_sorted.dropna(subset=['next_stop_idx'])\n",
    "unique_edges = edges_df[['stop_idx', 'next_stop_idx']].drop_duplicates()\n",
    "edge_index = torch.tensor(unique_edges.values.T, dtype=torch.long)\n",
    "\n",
    "# Load to GPU\n",
    "graph_data = Data(x=x, edge_index=edge_index).to(device)\n",
    "logger.info(f\"Graph on GPU: {graph_data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbc6efc",
   "metadata": {},
   "source": [
    "## STEP 3: Model definition (Context-aware GAT)\n",
    "Use attention-based message passing to produce a stop embedding, then fuse it with per-observation context.\n",
    "\n",
    "- Spatial encoder: 2-layer GAT over the stop graph\n",
    "- Fusion: concatenate stop embedding + context features\n",
    "- Head: small MLP regressor to predict delay seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77cd4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STEP 4: GNN MODEL V2 ARCHITECTURE\n",
    "# =============================================================================\n",
    "logger.info(\"--- Defining Model V2 (Wider Capacity) ---\")\n",
    "\n",
    "class ContextAwareGAT_V2(torch.nn.Module):\n",
    "    def __init__(self, num_node_features, num_context_features):\n",
    "        super(ContextAwareGAT_V2, self).__init__()\n",
    "        \n",
    "        # 1. Graph Layers (Increased Width: 32 -> 64)\n",
    "        # Heads=4, so internal dimension is 64*4 = 256\n",
    "        self.gat1 = GATConv(num_node_features, 64, heads=4, dropout=0.2) \n",
    "        self.gat2 = GATConv(64 * 4, 128, heads=1, concat=False, dropout=0.2)\n",
    "        \n",
    "        # 2. Fusion (Graph=128 + Context)\n",
    "        fusion_dim = 128 + num_context_features\n",
    "        \n",
    "        # 3. Deeper Regression Head\n",
    "        self.fc1 = torch.nn.Linear(fusion_dim, 256)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(256)\n",
    "        \n",
    "        self.fc2 = torch.nn.Linear(256, 128)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(128)\n",
    "        \n",
    "        self.fc3 = torch.nn.Linear(128, 64)\n",
    "        self.fc_out = torch.nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x, edge_index, context_features, stop_indices):\n",
    "        # Graph Phase\n",
    "        x = self.gat1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = self.gat2(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        \n",
    "        # Fusion Phase\n",
    "        batch_embeddings = x[stop_indices]\n",
    "        combined = torch.cat([batch_embeddings, context_features], dim=1)\n",
    "        \n",
    "        # Regression Phase\n",
    "        out = self.fc1(combined)\n",
    "        out = self.bn1(out)\n",
    "        out = F.elu(out)\n",
    "        \n",
    "        out = self.fc2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = F.elu(out)\n",
    "        \n",
    "        out = self.fc3(out)\n",
    "        out = F.elu(out)\n",
    "        \n",
    "        return self.fc_out(out)\n",
    "\n",
    "# Define Context Features (6 Total now)\n",
    "context_cols = ['hour_sin', 'hour_cos', 'day_sin', 'day_cos', 'prev_delay_scaled', 'seq_scaled']\n",
    "num_context = len(context_cols)\n",
    "\n",
    "model = ContextAwareGAT_V2(num_node_features=3, num_context_features=num_context).to(device)\n",
    "logger.info(f\"Model V2 Initialized. Context Features: {num_context}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678911d6",
   "metadata": {},
   "source": [
    "## STEP 4: Training (train/val/test + scheduler)\n",
    "Train with MAE (L1 loss) and monitor validation MAE for `ReduceLROnPlateau`.\n",
    "\n",
    "- Data flow: graph stays on GPU; batches stream `context_features` + `stop_indices`\n",
    "- Splits: train/val/test with fixed seed for reproducibility\n",
    "- Logging: per-epoch train MAE, val MAE, best val, and LR changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19b0073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STEP 4: TRAINING WITH SCHEDULER (VAL-AWARE)\n",
    "# =============================================================================\n",
    "logger.info(\"--- Preparing V2 Training Loop (Train/Val/Test + Plateau Monitoring) ---\")\n",
    "\n",
    "# -------------------------\n",
    "# Config-driven hyperparams\n",
    "# -------------------------\n",
    "random_state = getattr(config, 'RANDOM_STATE', getattr(config, 'SEED', 42))\n",
    "test_size = float(getattr(config, 'TEST_SIZE', 0.2))\n",
    "val_size = float(getattr(config, 'VAL_SIZE', 0.1))  # fraction of total rows\n",
    "\n",
    "batch_size = int(getattr(config, 'GNN_V2_BATCH_SIZE', 16384))\n",
    "num_epochs = int(getattr(config, 'GNN_V2_NUM_EPOCHS', 50))\n",
    "learning_rate = float(getattr(config, 'GNN_V2_LR', 0.003))\n",
    "weight_decay = float(getattr(config, 'GNN_V2_WEIGHT_DECAY', getattr(config, 'WEIGHT_DECAY', 0.0)))\n",
    "num_workers = int(getattr(config, 'NUM_WORKERS', 4))\n",
    "pin_memory = bool(getattr(config, 'PIN_MEMORY', True))\n",
    "\n",
    "sched_factor = float(getattr(config, 'GNN_V2_SCHED_FACTOR', 0.5))\n",
    "sched_patience = int(getattr(config, 'GNN_V2_SCHED_PATIENCE', 3))\n",
    "sched_threshold = float(getattr(config, 'GNN_V2_SCHED_THRESHOLD', 1e-4))\n",
    "sched_min_lr = float(getattr(config, 'GNN_V2_SCHED_MIN_LR', 1e-6))\n",
    "sched_cooldown = int(getattr(config, 'GNN_V2_SCHED_COOLDOWN', 0))\n",
    "champion_mae = float(getattr(config, 'CHAMPION_MAE', 43.18))\n",
    "\n",
    "logger.info(\n",
    "    \"Hyperparams | \"\n",
    "    f\"epochs={num_epochs} batch_size={batch_size} lr={learning_rate} wd={weight_decay} \"\n",
    "    f\"test_size={test_size} val_size={val_size} seed={random_state} \"\n",
    "    f\"plateau(factor={sched_factor}, patience={sched_patience}, threshold={sched_threshold}, min_lr={sched_min_lr}, cooldown={sched_cooldown})\"\n",
    " )\n",
    "\n",
    "# -------------------------\n",
    "# Prepare data arrays\n",
    "# -------------------------\n",
    "X_context = df[context_cols].values\n",
    "X_stop_idx = df['stop_idx'].values\n",
    "y_target = df['delay_seconds'].values\n",
    "\n",
    "indices = np.arange(len(df))\n",
    "trainval_idx, test_idx = train_test_split(indices, test_size=test_size, random_state=random_state)\n",
    "\n",
    "# Convert val_size (global) into fraction of trainval\n",
    "val_rel = val_size / max(1e-12, (1.0 - test_size))\n",
    "val_rel = min(max(val_rel, 0.0), 0.5)  # keep sane\n",
    "train_idx, val_idx = train_test_split(trainval_idx, test_size=val_rel, random_state=random_state)\n",
    "\n",
    "logger.info(f\"Split sizes | train={len(train_idx)} val={len(val_idx)} test={len(test_idx)}\")\n",
    "\n",
    "# -------------------------\n",
    "# Tensors & loaders\n",
    "# -------------------------\n",
    "def make_tensors(idxs):\n",
    "    ctx = torch.tensor(X_context[idxs], dtype=torch.float32)\n",
    "    stp = torch.tensor(X_stop_idx[idxs], dtype=torch.long)\n",
    "    yt = torch.tensor(y_target[idxs], dtype=torch.float32).view(-1, 1)\n",
    "    return ctx, stp, yt\n",
    "\n",
    "train_context, train_stop_indices, y_train_tensor = make_tensors(train_idx)\n",
    "val_context, val_stop_indices, y_val_tensor = make_tensors(val_idx)\n",
    "test_context, test_stop_indices, y_test_tensor = make_tensors(test_idx)\n",
    "\n",
    "train_dataset = TensorDataset(train_context, train_stop_indices, y_train_tensor)\n",
    "val_dataset = TensorDataset(val_context, val_stop_indices, y_val_tensor)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory,\n",
    "    drop_last=False,\n",
    " )\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory,\n",
    "    drop_last=False,\n",
    " )\n",
    "\n",
    "# -------------------------\n",
    "# Optimizer & scheduler\n",
    "# -------------------------\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "scheduler = ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',\n",
    "    factor=sched_factor,\n",
    "    patience=sched_patience,\n",
    "    threshold=sched_threshold,\n",
    "    cooldown=sched_cooldown,\n",
    "    min_lr=sched_min_lr,\n",
    " )\n",
    "criterion = torch.nn.L1Loss()\n",
    "\n",
    "# Log model size (useful for thesis + reproducibility)\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "logger.info(f\"Model parameters | trainable={trainable_params:,} total={total_params:,}\")\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_mae(loader) -> float:\n",
    "    model.eval()\n",
    "    total = 0.0\n",
    "    n_batches = 0\n",
    "    for context_batch, stop_idx_batch, y_batch in loader:\n",
    "        context_batch = context_batch.to(device, non_blocking=True)\n",
    "        stop_idx_batch = stop_idx_batch.to(device, non_blocking=True)\n",
    "        y_batch = y_batch.to(device, non_blocking=True)\n",
    "        out = model(graph_data.x, graph_data.edge_index, context_batch, stop_idx_batch)\n",
    "        loss = criterion(out, y_batch)\n",
    "        total += float(loss.item())\n",
    "        n_batches += 1\n",
    "    return total / max(1, n_batches)\n",
    "\n",
    "logger.info(\"Starting Training with ReduceLROnPlateau (stepped on VAL MAE)...\")\n",
    "\n",
    "best_val = float('inf')\n",
    "history = {'train_mae': [], 'val_mae': [], 'lr': []}\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_train = 0.0\n",
    "    n_train_batches = 0\n",
    "\n",
    "    for context_batch, stop_idx_batch, y_batch in train_loader:\n",
    "        context_batch = context_batch.to(device, non_blocking=True)\n",
    "        stop_idx_batch = stop_idx_batch.to(device, non_blocking=True)\n",
    "        y_batch = y_batch.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        out = model(graph_data.x, graph_data.edge_index, context_batch, stop_idx_batch)\n",
    "        loss = criterion(out, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train += float(loss.item())\n",
    "        n_train_batches += 1\n",
    "\n",
    "    train_mae = total_train / max(1, n_train_batches)\n",
    "    val_mae = evaluate_mae(val_loader)\n",
    "\n",
    "    lr_before = float(optimizer.param_groups[0]['lr'])\n",
    "    scheduler.step(val_mae)\n",
    "    lr_after = float(optimizer.param_groups[0]['lr'])\n",
    "    lr_note = \"LR↓\" if lr_after < lr_before else \"LR=\"\n",
    "\n",
    "    improved = val_mae < (best_val - sched_threshold)\n",
    "    if improved:\n",
    "        best_val = val_mae\n",
    "\n",
    "    # Plateau diagnostics\n",
    "    sched_best = getattr(scheduler, 'best', None)\n",
    "    bad_epochs = getattr(scheduler, 'num_bad_epochs', None)\n",
    "    cooldown = getattr(scheduler, 'cooldown_counter', None)\n",
    "    delta_to_champion = val_mae - champion_mae\n",
    "\n",
    "    history['train_mae'].append(train_mae)\n",
    "    history['val_mae'].append(val_mae)\n",
    "    history['lr'].append(lr_after)\n",
    "\n",
    "    logger.info(\n",
    "        f\"Epoch {epoch+1:03d}/{num_epochs} | \"\n",
    "        f\"train_MAE={train_mae:.2f}s | val_MAE={val_mae:.2f}s | best_val={best_val:.2f}s | \"\n",
    "        f\"Δ_vs_{champion_mae:.2f}s={delta_to_champion:+.2f}s | \"\n",
    "        f\"{lr_note} {lr_after:.6g} | bad_epochs={bad_epochs} | sched_best={sched_best} | cooldown={cooldown}\"\n",
    "    )\n",
    "\n",
    "logger.info(\"V2 Training Complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0a5491",
   "metadata": {},
   "source": [
    "## STEP 5: Evaluation\n",
    "Evaluate on the held-out test split and save a diagnostics figure.\n",
    "\n",
    "- Metrics: MAE / RMSE / $R^2$\n",
    "- Compare: delta vs. the Random Forest baseline (`CHAMPION_MAE`)\n",
    "- Artifact: save `plots/gnn_model_v2_diagnostics.png`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f202826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STEP 5: MODEL V2 EVALUATION\n",
    "# =============================================================================\n",
    "\n",
    "logger.info(\"--- Starting Model V2 Evaluation on Test Set ---\")\n",
    "\n",
    "# Config-driven evaluation settings\n",
    "batch_size = int(getattr(config, 'GNN_V2_EVAL_BATCH_SIZE', getattr(config, 'GNN_V2_BATCH_SIZE', 16384)))\n",
    "num_workers = int(getattr(config, 'NUM_WORKERS', 4))\n",
    "pin_memory = bool(getattr(config, 'PIN_MEMORY', True))\n",
    "plots_dir = getattr(config, 'PLOTS_DIR', os.path.join(os.getcwd(), 'plots'))\n",
    "os.makedirs(plots_dir, exist_ok=True)\n",
    "\n",
    "# 1. Create Test Loader\n",
    "test_dataset = TensorDataset(test_context, test_stop_indices, y_test_tensor)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory,\n",
    " )\n",
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "# 2. Run Inference\n",
    "logger.info(\"Running inference...\")\n",
    "with torch.no_grad():\n",
    "    for context_batch, stop_idx_batch, y_batch in test_loader:\n",
    "        context_batch = context_batch.to(device, non_blocking=True)\n",
    "        stop_idx_batch = stop_idx_batch.to(device, non_blocking=True)\n",
    "\n",
    "        # Forward Pass\n",
    "        out = model(graph_data.x, graph_data.edge_index, context_batch, stop_idx_batch)\n",
    "\n",
    "        all_preds.append(out.cpu().numpy())\n",
    "        all_targets.append(y_batch.cpu().numpy())\n",
    "\n",
    "# Concatenate\n",
    "y_pred = np.vstack(all_preds).flatten()\n",
    "y_true = np.vstack(all_targets).flatten()\n",
    "\n",
    "# 3. Calculate Metrics\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "logger.info(\"--- FINAL GNN MODEL V2 RESULTS ---\")\n",
    "logger.info(f\"MAE (Mean Absolute Error): {mae:.2f} seconds\")\n",
    "logger.info(f\"RMSE (Root Mean Sq Error): {rmse:.2f} seconds\")\n",
    "logger.info(f\"R² Score:                  {r2:.4f}\")\n",
    "\n",
    "# Comparisons\n",
    "champion_mae = float(getattr(config, 'CHAMPION_MAE', 43.18))\n",
    "logger.info(f\"VS Baseline GNN (121s):     {121 - mae:+.2f}s improvement\")\n",
    "logger.info(f\"VS Context RF ({champion_mae:.2f}s):  {champion_mae - mae:+.2f}s difference\")\n",
    "\n",
    "# 4. Generate Diagnostic Plots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "\n",
    "# Subsample for plotting\n",
    "plot_indices = np.random.choice(len(y_pred), size=min(5000, len(y_pred)), replace=False)\n",
    "y_pred_sub = y_pred[plot_indices]\n",
    "y_true_sub = y_true[plot_indices]\n",
    "residuals = y_true_sub - y_pred_sub\n",
    "\n",
    "# --- Plot A: Predicted vs Actual ---\n",
    "axes[0].scatter(y_true_sub, y_pred_sub, alpha=0.3, s=10, color='blue')\n",
    "axes[0].plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'r--', lw=2, label='Perfect Fit')\n",
    "axes[0].set_title(f\"GNN Model V2: Predicted vs Actual\\nMAE: {mae:.2f}s | R²: {r2:.2f}\")\n",
    "axes[0].set_xlabel(\"Actual Delay (s)\")\n",
    "axes[0].set_ylabel(\"Predicted Delay (s)\")\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# --- Plot B: Residuals ---\n",
    "axes[1].scatter(y_pred_sub, residuals, alpha=0.3, s=10, color='purple')\n",
    "axes[1].axhline(0, color='red', linestyle='--', lw=2)\n",
    "axes[1].set_title(\"Residuals vs Predictions\")\n",
    "axes[1].set_xlabel(\"Predicted Delay (s)\")\n",
    "axes[1].set_ylabel(\"Error (s)\")\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# --- Plot C: Error Distribution ---\n",
    "sns.histplot(residuals, bins=50, kde=True, ax=axes[2], color='green')\n",
    "axes[2].axvline(0, color='red', linestyle='--', lw=2)\n",
    "axes[2].set_title(\"Error Distribution\")\n",
    "axes[2].set_xlabel(\"Error (s)\")\n",
    "\n",
    "fig.tight_layout()\n",
    "plot_path = os.path.join(plots_dir, \"gnn_model_v2_diagnostics.png\")\n",
    "fig.savefig(plot_path, dpi=150)\n",
    "plt.close(fig)\n",
    "logger.info(f\"Saved diagnostic plots to: {plot_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
