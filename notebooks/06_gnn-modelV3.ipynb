{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1109ea72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "\n",
    "# GNN / PyG\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GATConv\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Torch utils\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# Project imports (config + logger)\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "import config\n",
    "from utils import setup_logger\n",
    "\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4788e1a3",
   "metadata": {},
   "source": [
    "# GNN Model V3 — Temporal + Spatial Learning\n",
    "\n",
    "This notebook implements a stronger iteration of our GNN by adding **temporal memory** on top of the spatial stop-graph model.\n",
    "\n",
    "## What changes vs Model V2\n",
    "- **Model V2**: Spatial stop embeddings (GAT) + per-row context (lag + time + sequence index).\n",
    "- **Model V3**: Spatial stop embeddings (GAT) + **windowed temporal encoder (GRU)** over each trip’s recent context history.\n",
    "\n",
    "## Why this can improve MAE\n",
    "Transit delay is dynamic: being late at the previous stop and how that lateness evolves across the last few stops are strong predictors of the next delay. A GRU can encode this short-term evolution more directly than a single lag value.\n",
    "\n",
    "All hyperparameters and paths are loaded from `src/config.py` (with `GNN_V3_*` keys)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928767f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STEP 0: RUNTIME SETUP (CONFIG + LOGGING)\n",
    "# =============================================================================\n",
    "\n",
    "log_dir = getattr(config, 'LOG_DIR', 'log')\n",
    "logger = setup_logger(\n",
    "    name='gnn_model_v3',\n",
    "    log_dir=log_dir,\n",
    "    filename='gnn_model_v3_training.log',\n",
    "    level=logging.INFO,\n",
    "    mode='w',\n",
    ")\n",
    "\n",
    "seed = int(getattr(config, 'SEED', 42))\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "logger.info('--- STARTING GNN MODEL V3 TRAINING ---')\n",
    "logger.info(f\"Device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    logger.info(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "plots_dir = getattr(config, 'PLOTS_DIR', os.path.join(os.getcwd(), 'plots'))\n",
    "os.makedirs(plots_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a53668",
   "metadata": {},
   "source": [
    "## 1. Data Loading + Canonical Sorting\n",
    "\n",
    "We load the cleaned dataset and enforce a strict sort by `(trip_id, timestamp)` so that temporal features (lags, deltas, rolling windows) are correct and reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5393488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STEP 1: LOAD DATA\n",
    "# =============================================================================\n",
    "\n",
    "clean_path = getattr(\n",
    "    config,\n",
    "    'CLEANED_CSV_PATH',\n",
    "    os.path.join(getattr(config, 'DATA_DIR', 'data'), 'vehicle_positions_cleaned.csv')\n",
    ")\n",
    "logger.info(f\"Loading data from: {clean_path}\")\n",
    "df = pd.read_csv(clean_path)\n",
    "\n",
    "required_cols = ['timestamp', 'trip_id', 'delay_seconds', 'latitude', 'longitude']\n",
    "missing_required = [c for c in required_cols if c not in df.columns]\n",
    "if missing_required:\n",
    "    raise ValueError(f\"Missing required columns: {missing_required}\")\n",
    "\n",
    "# Choose stop column name consistently\n",
    "stop_col = 'last_stop_id' if 'last_stop_id' in df.columns else 'stop_id'\n",
    "if stop_col not in df.columns:\n",
    "    raise ValueError(\"No stop column found (expected 'last_stop_id' or 'stop_id')\")\n",
    "\n",
    "# Basic cleanup (keep minimal; do not silently change semantics)\n",
    "df = df.dropna(subset=['timestamp', 'trip_id', stop_col, 'delay_seconds', 'latitude', 'longitude']).copy()\n",
    "df['dt'] = pd.to_datetime(df['timestamp'], errors='coerce')\n",
    "df = df.dropna(subset=['dt']).copy()\n",
    "\n",
    "# Canonical sort for temporal feature engineering\n",
    "df = df.sort_values(['trip_id', 'dt']).reset_index(drop=True)\n",
    "logger.info(f\"Rows after basic cleanup: {len(df):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b74cf4",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering (V3: Temporal-Signal Upgrade)\n",
    "\n",
    "Model V3 adds features that help a temporal encoder learn *how delay evolves* within a trip:\n",
    "\n",
    "- **Lag**: previous stop delay (`prev_stop_delay`).\n",
    "- **Rolling lag**: short-window mean of lag (`rolling_prev_delay`) to stabilize noise.\n",
    "- **Time delta**: seconds since the previous observation in the trip (`time_delta_sec`).\n",
    "- **Progress**: normalized trip progress $\\in [0,1]$ so the model can compare different trip lengths.\n",
    "- **Cyclical time**: sine/cosine for hour and day-of-week.\n",
    "\n",
    "We then scale static node features and dynamic context features for stable training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a3e2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STEP 2: FEATURE ENGINEERING (V3)\n",
    "# =============================================================================\n",
    "\n",
    "logger.info('--- Generating V3 Features ---')\n",
    "\n",
    "# -------------------------\n",
    "# Config-driven knobs\n",
    "# -------------------------\n",
    "lag_clip_min = int(getattr(config, 'GNN_V3_LAG_CLIP_MIN', -1800))\n",
    "lag_clip_max = int(getattr(config, 'GNN_V3_LAG_CLIP_MAX', 3600))\n",
    "time_delta_clip = int(getattr(config, 'GNN_V3_TIME_DELTA_CLIP_SEC', 900))\n",
    "rolling_w = int(getattr(config, 'GNN_V3_ROLLING_LAG_WINDOW', 3))\n",
    "\n",
    "# 1) Lag feature\n",
    "df['prev_stop_delay'] = df.groupby('trip_id')['delay_seconds'].shift(1).fillna(0.0)\n",
    "\n",
    "# 2) Rolling lag mean (using only past information)\n",
    "df['rolling_prev_delay'] = (\n",
    "    df.groupby('trip_id')['prev_stop_delay']\n",
    "      .rolling(window=rolling_w, min_periods=1)\n",
    "      .mean()\n",
    "      .reset_index(level=0, drop=True)\n",
    ")\n",
    "\n",
    "# 3) Time delta between consecutive observations within trip\n",
    "df['time_delta_sec'] = df.groupby('trip_id')['dt'].diff().dt.total_seconds().fillna(0.0)\n",
    "df['time_delta_sec'] = df['time_delta_sec'].clip(0, time_delta_clip)\n",
    "\n",
    "# 4) Progress in trip (normalized)\n",
    "trip_len = df.groupby('trip_id')[stop_col].transform('size').astype(np.float32)\n",
    "stop_sequence = df.groupby('trip_id').cumcount().astype(np.float32)\n",
    "df['progress'] = np.where(trip_len > 1, stop_sequence / (trip_len - 1.0), 0.0)\n",
    "\n",
    "# 5) Cyclical time embeddings\n",
    "df['hour'] = df['dt'].dt.hour\n",
    "df['day_of_week'] = df['dt'].dt.dayofweek\n",
    "df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)\n",
    "df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)\n",
    "df['day_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7)\n",
    "df['day_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7)\n",
    "\n",
    "# 6) Stop-level historical mean delay (static signal)\n",
    "global_mean = float(df['delay_seconds'].mean())\n",
    "stop_history = df.groupby(stop_col)['delay_seconds'].mean()\n",
    "df['history_mean'] = df[stop_col].map(stop_history).fillna(global_mean)\n",
    "\n",
    "# -------------------------\n",
    "# Scaling\n",
    "# -------------------------\n",
    "logger.info('Scaling features...')\n",
    "\n",
    "# A) Node features (static): lat/lon + history\n",
    "scaler_nodes = StandardScaler()\n",
    "df[['lat_scaled', 'lon_scaled', 'hist_scaled']] = scaler_nodes.fit_transform(\n",
    "    df[['latitude', 'longitude', 'history_mean']]\n",
    " )\n",
    "\n",
    "# B) Dynamic features (context stream)\n",
    "df['prev_delay_clipped'] = df['prev_stop_delay'].clip(lag_clip_min, lag_clip_max)\n",
    "df['rolling_prev_delay_clipped'] = df['rolling_prev_delay'].clip(lag_clip_min, lag_clip_max)\n",
    "\n",
    "scaler_lag = StandardScaler()\n",
    "df['prev_delay_scaled'] = scaler_lag.fit_transform(df[['prev_delay_clipped']])\n",
    "\n",
    "scaler_roll = StandardScaler()\n",
    "df['rolling_prev_delay_scaled'] = scaler_roll.fit_transform(df[['rolling_prev_delay_clipped']])\n",
    "\n",
    "scaler_delta = StandardScaler()\n",
    "df['time_delta_scaled'] = scaler_delta.fit_transform(df[['time_delta_sec']])\n",
    "\n",
    "scaler_prog = StandardScaler()\n",
    "df['progress_scaled'] = scaler_prog.fit_transform(df[['progress']])\n",
    "\n",
    "logger.info('Feature engineering complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3b448a",
   "metadata": {},
   "source": [
    "## 3. Construct the Static Stop Graph\n",
    "\n",
    "We build a directed stop graph once and keep it on the GPU. Each training example will reference a stop index (node) plus a **temporal context window**.\n",
    "\n",
    "- **Nodes**: unique stops, with static features `[lat_scaled, lon_scaled, hist_scaled]`.\n",
    "- **Edges**: inferred from sequential stop transitions within trips (A → B if B follows A)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0836582f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STEP 3: GRAPH CONSTRUCTION\n",
    "# =============================================================================\n",
    "\n",
    "logger.info('--- Constructing Transit Graph ---')\n",
    "\n",
    "stop_encoder = LabelEncoder()\n",
    "df['stop_idx'] = stop_encoder.fit_transform(df[stop_col].astype(str))\n",
    "\n",
    "# Node feature tensor (mean over rows that visit each stop)\n",
    "node_cols = ['lat_scaled', 'lon_scaled', 'hist_scaled']\n",
    "node_features_df = df.groupby('stop_idx')[node_cols].mean()\n",
    "x = torch.tensor(node_features_df.values, dtype=torch.float32)\n",
    "\n",
    "# Edges from sequential transitions within trip\n",
    "df_sorted = df.sort_values(by=['trip_id', 'dt']).copy()\n",
    "df_sorted['next_stop_idx'] = df_sorted.groupby('trip_id')['stop_idx'].shift(-1)\n",
    "edges_df = df_sorted.dropna(subset=['next_stop_idx'])\n",
    "unique_edges = edges_df[['stop_idx', 'next_stop_idx']].drop_duplicates()\n",
    "edge_index = torch.tensor(unique_edges.values.T, dtype=torch.long)\n",
    "\n",
    "graph_data = Data(x=x, edge_index=edge_index).to(device)\n",
    "logger.info(f\"Graph ready | nodes={graph_data.num_nodes:,} edges={graph_data.num_edges:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6a6e45",
   "metadata": {},
   "source": [
    "## 4. Build a Windowed Temporal Dataset (Per-Trip Sequences)\n",
    "\n",
    "The key upgrade in Model V3 is that we do not feed only a single “previous delay” scalar.\n",
    "Instead, we create a short window of recent context for each row (within the same `trip_id`) and encode it with a GRU.\n",
    "\n",
    "**How the windows work**\n",
    "- For each row at position $t$ in a trip, we take the last $k$ timesteps of context features up to $t$ (left-padded with zeros if needed).\n",
    "- We also store the true window length (for packing into the GRU).\n",
    "- The static graph stays unchanged; each example also carries a `stop_idx` to pull the correct node embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26af08bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STEP 4: WINDOWED SEQUENCE DATASET (V3)\n",
    "# =============================================================================\n",
    "\n",
    "logger.info('--- Preparing lazy temporal windows for GRU ---')\n",
    "\n",
    "seq_len = int(getattr(config, 'GNN_V3_SEQ_LEN', 12))\n",
    "split_by_trip = bool(getattr(config, 'GNN_V3_SPLIT_BY_TRIP', True))\n",
    "\n",
    "# Dynamic context features to be fed as a temporal sequence\n",
    "context_seq_cols = [\n",
    "    'hour_sin', 'hour_cos', 'day_sin', 'day_cos',\n",
    "    'prev_delay_scaled', 'rolling_prev_delay_scaled',\n",
    "    'time_delta_scaled', 'progress_scaled',\n",
    "]\n",
    "missing_ctx = [c for c in context_seq_cols if c not in df.columns]\n",
    "if missing_ctx:\n",
    "    raise ValueError(f\"Missing context columns for V3: {missing_ctx}\")\n",
    "\n",
    "# IMPORTANT: With ~15M rows, pre-building X_seq_all would allocate multiple GB and can freeze VS Code.\n",
    "# Instead, we keep only the base arrays and build windows on-the-fly per batch via a custom collate_fn.\n",
    "\n",
    "X_ctx_base = df[context_seq_cols].to_numpy(dtype=np.float32, copy=False)\n",
    "stop_idx_base = df['stop_idx'].to_numpy(dtype=np.int64, copy=False)\n",
    "y_base = df['delay_seconds'].to_numpy(dtype=np.float32, copy=False).reshape(-1, 1)\n",
    "\n",
    "n = len(df)\n",
    "num_feat = len(context_seq_cols)\n",
    "logger.info(f\"Base arrays | rows={n:,} seq_len={seq_len} features={num_feat}\")\n",
    "\n",
    "# Precompute trip segment info (cheap vs building a (n, seq_len, feat) tensor)\n",
    "trip_codes, _ = pd.factorize(df['trip_id'].astype(str), sort=False)\n",
    "change = np.flatnonzero(np.diff(trip_codes) != 0) + 1\n",
    "starts = np.concatenate(([0], change))\n",
    "ends = np.concatenate((change, [n]))\n",
    "\n",
    "trip_start = np.empty((n,), dtype=np.int64)\n",
    "pos_in_trip = np.empty((n,), dtype=np.int64)\n",
    "for s, e in zip(starts, ends):\n",
    "    trip_start[s:e] = s\n",
    "    pos_in_trip[s:e] = np.arange(e - s, dtype=np.int64)\n",
    "\n",
    "# -------------------------\n",
    "# Train / Val / Test split\n",
    "# -------------------------\n",
    "random_state = int(getattr(config, 'RANDOM_STATE', getattr(config, 'SEED', 42)))\n",
    "test_size = float(getattr(config, 'TEST_SIZE', 0.2))\n",
    "val_size = float(getattr(config, 'VAL_SIZE', 0.1))  # fraction of total rows\n",
    "indices = np.arange(n)\n",
    "\n",
    "if split_by_trip:\n",
    "    trips = df['trip_id'].astype(str).unique()\n",
    "    trainval_trips, test_trips = train_test_split(trips, test_size=test_size, random_state=random_state)\n",
    "    val_rel = val_size / max(1e-12, (1.0 - test_size))\n",
    "    val_rel = min(max(val_rel, 0.0), 0.5)\n",
    "    train_trips, val_trips = train_test_split(trainval_trips, test_size=val_rel, random_state=random_state)\n",
    "\n",
    "    train_mask = df['trip_id'].astype(str).isin(train_trips).to_numpy()\n",
    "    val_mask = df['trip_id'].astype(str).isin(val_trips).to_numpy()\n",
    "    test_mask = df['trip_id'].astype(str).isin(test_trips).to_numpy()\n",
    "\n",
    "    train_idx = indices[train_mask]\n",
    "    val_idx = indices[val_mask]\n",
    "    test_idx = indices[test_mask]\n",
    "else:\n",
    "    trainval_idx, test_idx = train_test_split(indices, test_size=test_size, random_state=random_state)\n",
    "    val_rel = val_size / max(1e-12, (1.0 - test_size))\n",
    "    val_rel = min(max(val_rel, 0.0), 0.5)\n",
    "    train_idx, val_idx = train_test_split(trainval_idx, test_size=val_rel, random_state=random_state)\n",
    "\n",
    "logger.info(f\"Split sizes | train={len(train_idx):,} val={len(val_idx):,} test={len(test_idx):,} | split_by_trip={split_by_trip}\")\n",
    "\n",
    "class RowIndexDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, row_indices: np.ndarray):\n",
    "        self.row_indices = row_indices\n",
    "    def __len__(self):\n",
    "        return int(self.row_indices.shape[0])\n",
    "    def __getitem__(self, i: int):\n",
    "        return int(self.row_indices[i])\n",
    "\n",
    "def make_window_batch(row_indices: list[int]):\n",
    "    # Builds (B, seq_len, num_feat) lazily for this batch only.\n",
    "    batch_size = len(row_indices)\n",
    "    seq = np.zeros((batch_size, seq_len, num_feat), dtype=np.float32)\n",
    "    lengths = np.empty((batch_size,), dtype=np.int64)\n",
    "    stop_idx = np.empty((batch_size,), dtype=np.int64)\n",
    "    y = np.empty((batch_size, 1), dtype=np.float32)\n",
    "\n",
    "    for b, r in enumerate(row_indices):\n",
    "        pos = int(pos_in_trip[r])\n",
    "        L = seq_len if pos + 1 >= seq_len else (pos + 1)\n",
    "        start = r - L + 1\n",
    "        seq[b, -L:, :] = X_ctx_base[start : r + 1]\n",
    "        lengths[b] = L\n",
    "        stop_idx[b] = stop_idx_base[r]\n",
    "        y[b, 0] = y_base[r, 0]\n",
    "\n",
    "    return (\n",
    "        torch.from_numpy(seq),\n",
    "        torch.from_numpy(lengths),\n",
    "        torch.from_numpy(stop_idx),\n",
    "        torch.from_numpy(y),\n",
    "    )\n",
    "\n",
    "train_dataset = RowIndexDataset(train_idx)\n",
    "val_dataset = RowIndexDataset(val_idx)\n",
    "test_dataset = RowIndexDataset(test_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34868288",
   "metadata": {},
   "source": [
    "## 5. Define the V3 Architecture (GAT + GRU Fusion)\n",
    "\n",
    "Model V3 has two branches:\n",
    "\n",
    "1) **Spatial branch (GAT)**: learns a stop embedding from the static stop graph.\n",
    "2) **Temporal branch (GRU)**: learns a compact state from the last $k$ steps of context.\n",
    "\n",
    "We then **fuse** these representations and regress the delay in seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a92149b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STEP 5: MODEL DEFINITION (V3)\n",
    "# =============================================================================\n",
    "\n",
    "logger.info('--- Defining Model V3 (GAT + GRU) ---')\n",
    "\n",
    "dropout = float(getattr(config, 'GNN_V3_DROPOUT', 0.2))\n",
    "gru_hidden = int(getattr(config, 'GNN_V3_GRU_HIDDEN', 64))\n",
    "num_seq_features = len(context_seq_cols)\n",
    "\n",
    "class ContextAwareGAT_GRU_V3(nn.Module):\n",
    "    def __init__(self, num_node_features: int, num_seq_features: int, gru_hidden: int, dropout: float):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Spatial encoder (similar capacity to V2)\n",
    "        self.gat1 = GATConv(num_node_features, 64, heads=4, dropout=dropout)\n",
    "        self.gat2 = GATConv(64 * 4, 128, heads=1, concat=False, dropout=dropout)\n",
    "        \n",
    "        # Temporal encoder\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=num_seq_features,\n",
    "            hidden_size=gru_hidden,\n",
    "            num_layers=1,\n",
    "            batch_first=True,\n",
    "            dropout=0.0,\n",
    "        )\n",
    "        \n",
    "        fusion_dim = 128 + gru_hidden\n",
    "        self.fc1 = nn.Linear(fusion_dim, 256)\n",
    "        self.bn1 = nn.BatchNorm1d(256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc_out = nn.Linear(64, 1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x_nodes, edge_index, seq_batch, lengths, stop_indices):\n",
    "        # Spatial\n",
    "        x = self.gat1(x_nodes, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = self.gat2(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        stop_emb = x[stop_indices]  # [B, 128]\n",
    "        \n",
    "        # Temporal (pack padded sequence for efficiency/correctness)\n",
    "        # lengths is [B] with values in [1, seq_len]\n",
    "        lengths_cpu = lengths.detach().to('cpu')\n",
    "        packed = pack_padded_sequence(\n",
    "            seq_batch,\n",
    "            lengths=lengths_cpu,\n",
    "            batch_first=True,\n",
    "            enforce_sorted=False,\n",
    "        )\n",
    "        _, h_n = self.gru(packed)\n",
    "        temp_emb = h_n[-1]  # [B, gru_hidden]\n",
    "        \n",
    "        # Fuse + regress\n",
    "        fused = torch.cat([stop_emb, temp_emb], dim=1)\n",
    "        out = self.dropout(F.elu(self.bn1(self.fc1(fused))))\n",
    "        out = self.dropout(F.elu(self.bn2(self.fc2(out))))\n",
    "        out = self.dropout(F.elu(self.fc3(out)))\n",
    "        return self.fc_out(out)\n",
    "\n",
    "model = ContextAwareGAT_GRU_V3(\n",
    "    num_node_features=graph_data.x.shape[1],\n",
    "    num_seq_features=num_seq_features,\n",
    "    gru_hidden=gru_hidden,\n",
    "    dropout=dropout,\n",
    ").to(device)\n",
    "\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "logger.info(f\"Model V3 initialized | params(trainable)={trainable_params:,} | seq_len={seq_len} | seq_features={num_seq_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738eaefc",
   "metadata": {},
   "source": [
    "## 6. Training Loop (Val-Aware Scheduler)\n",
    "\n",
    "We use the same training philosophy as Model V2:\n",
    "- Stream batches of lightweight tensors with a `DataLoader`.\n",
    "- Keep the graph on the GPU.\n",
    "- Optimize MAE (L1 loss).\n",
    "- Step `ReduceLROnPlateau` on **validation MAE** (not training loss)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa09715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STEP 6: TRAINING (V3)\n",
    "# =============================================================================\n",
    "\n",
    "logger.info('--- Preparing DataLoaders + Training ---')\n",
    "\n",
    "batch_size = int(getattr(config, 'GNN_V3_BATCH_SIZE', 4096))\n",
    "num_epochs = int(getattr(config, 'GNN_V3_NUM_EPOCHS', 50))\n",
    "learning_rate = float(getattr(config, 'GNN_V3_LR', 0.003))\n",
    "weight_decay = float(getattr(config, 'GNN_V3_WEIGHT_DECAY', 0.0))\n",
    "num_workers = int(getattr(config, 'NUM_WORKERS', 4))\n",
    "pin_memory = bool(getattr(config, 'PIN_MEMORY', True))\n",
    "\n",
    "sched_factor = float(getattr(config, 'GNN_V3_SCHED_FACTOR', 0.5))\n",
    "sched_patience = int(getattr(config, 'GNN_V3_SCHED_PATIENCE', 3))\n",
    "sched_threshold = float(getattr(config, 'GNN_V3_SCHED_THRESHOLD', 1e-4))\n",
    "sched_min_lr = float(getattr(config, 'GNN_V3_SCHED_MIN_LR', 1e-6))\n",
    "sched_cooldown = int(getattr(config, 'GNN_V3_SCHED_COOLDOWN', 0))\n",
    "champion_mae = float(getattr(config, 'CHAMPION_MAE', 43.18))\n",
    "\n",
    "logger.info(\n",
    "    \"Hyperparams | \"\n",
    "    f\"epochs={num_epochs} batch_size={batch_size} lr={learning_rate} wd={weight_decay} \"\n",
    "    f\"seq_len={seq_len} gru_hidden={gru_hidden} dropout={dropout} \"\n",
    "    f\"plateau(factor={sched_factor}, patience={sched_patience}, threshold={sched_threshold}, min_lr={sched_min_lr}, cooldown={sched_cooldown})\"\n",
    " )\n",
    "\n",
    "# DataLoaders build windows lazily via make_window_batch from Step 4\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory,\n",
    "    drop_last=False,\n",
    "    collate_fn=make_window_batch,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory,\n",
    "    drop_last=False,\n",
    "    collate_fn=make_window_batch,\n",
    ")\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "scheduler = ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',\n",
    "    factor=sched_factor,\n",
    "    patience=sched_patience,\n",
    "    threshold=sched_threshold,\n",
    "    cooldown=sched_cooldown,\n",
    "    min_lr=sched_min_lr,\n",
    ")\n",
    "criterion = nn.L1Loss()\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_mae(loader) -> float:\n",
    "    model.eval()\n",
    "    total = 0.0\n",
    "    n_batches = 0\n",
    "    for seq_batch, lengths, stop_idx, y_batch in loader:\n",
    "        seq_batch = seq_batch.to(device, non_blocking=True)\n",
    "        lengths = lengths.to(device, non_blocking=True)\n",
    "        stop_idx = stop_idx.to(device, non_blocking=True)\n",
    "        y_batch = y_batch.to(device, non_blocking=True)\n",
    "        out = model(graph_data.x, graph_data.edge_index, seq_batch, lengths, stop_idx)\n",
    "        loss = criterion(out, y_batch)\n",
    "        total += float(loss.item())\n",
    "        n_batches += 1\n",
    "    return total / max(1, n_batches)\n",
    "\n",
    "logger.info('Starting training (scheduler stepped on VAL MAE)...')\n",
    "best_val = float('inf')\n",
    "history = {'train_mae': [], 'val_mae': [], 'lr': []}\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_train = 0.0\n",
    "    n_train_batches = 0\n",
    "    for seq_batch, lengths, stop_idx, y_batch in train_loader:\n",
    "        seq_batch = seq_batch.to(device, non_blocking=True)\n",
    "        lengths = lengths.to(device, non_blocking=True)\n",
    "        stop_idx = stop_idx.to(device, non_blocking=True)\n",
    "        y_batch = y_batch.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        out = model(graph_data.x, graph_data.edge_index, seq_batch, lengths, stop_idx)\n",
    "        loss = criterion(out, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train += float(loss.item())\n",
    "        n_train_batches += 1\n",
    "\n",
    "    train_mae = total_train / max(1, n_train_batches)\n",
    "    val_mae = evaluate_mae(val_loader)\n",
    "\n",
    "    lr_before = float(optimizer.param_groups[0]['lr'])\n",
    "    scheduler.step(val_mae)\n",
    "    lr_after = float(optimizer.param_groups[0]['lr'])\n",
    "    lr_note = 'LR↓' if lr_after < lr_before else 'LR='\n",
    "    improved = val_mae < (best_val - sched_threshold)\n",
    "    if improved:\n",
    "        best_val = val_mae\n",
    "\n",
    "    sched_best = getattr(scheduler, 'best', None)\n",
    "    bad_epochs = getattr(scheduler, 'num_bad_epochs', None)\n",
    "    cooldown = getattr(scheduler, 'cooldown_counter', None)\n",
    "    delta_to_champion = val_mae - champion_mae\n",
    "\n",
    "    history['train_mae'].append(train_mae)\n",
    "    history['val_mae'].append(val_mae)\n",
    "    history['lr'].append(lr_after)\n",
    "\n",
    "    logger.info(\n",
    "        f\"Epoch {epoch+1:03d}/{num_epochs} | \"\n",
    "        f\"train_MAE={train_mae:.2f}s | val_MAE={val_mae:.2f}s | best_val={best_val:.2f}s | \"\n",
    "        f\"Δ_vs_{champion_mae:.2f}s={delta_to_champion:+.2f}s | \"\n",
    "        f\"{lr_note} {lr_after:.6g} | bad_epochs={bad_epochs} | sched_best={sched_best} | cooldown={cooldown}\"\n",
    "    )\n",
    "\n",
    "logger.info('V3 training complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a126a4da",
   "metadata": {},
   "source": [
    "## 7. Evaluation + Diagnostics Plot\n",
    "\n",
    "We evaluate on the held-out test set and save a diagnostic figure under `plots/` using an accurate filename:\n",
    "- `gnn_model_v3_diagnostics.png`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3921266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STEP 7: EVALUATION (V3)\n",
    "# =============================================================================\n",
    "\n",
    "logger.info('--- Starting Model V3 Evaluation on Test Set ---')\n",
    "\n",
    "eval_batch_size = int(getattr(config, 'GNN_V3_EVAL_BATCH_SIZE', getattr(config, 'GNN_V3_BATCH_SIZE', 4096)))\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=eval_batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory,\n",
    "    collate_fn=make_window_batch,\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "logger.info('Running inference...')\n",
    "with torch.no_grad():\n",
    "    for seq_batch, lengths, stop_idx, y_batch in test_loader:\n",
    "        seq_batch = seq_batch.to(device, non_blocking=True)\n",
    "        lengths = lengths.to(device, non_blocking=True)\n",
    "        stop_idx = stop_idx.to(device, non_blocking=True)\n",
    "        out = model(graph_data.x, graph_data.edge_index, seq_batch, lengths, stop_idx)\n",
    "        all_preds.append(out.detach().cpu().numpy())\n",
    "        all_targets.append(y_batch.detach().cpu().numpy())\n",
    "\n",
    "y_pred = np.vstack(all_preds).flatten()\n",
    "y_true = np.vstack(all_targets).flatten()\n",
    "\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "rmse = float(np.sqrt(mean_squared_error(y_true, y_pred)))\n",
    "r2 = float(r2_score(y_true, y_pred))\n",
    "\n",
    "logger.info('--- FINAL GNN MODEL V3 RESULTS ---')\n",
    "logger.info(f\"MAE (Mean Absolute Error): {mae:.2f} seconds\")\n",
    "logger.info(f\"RMSE (Root Mean Sq Error): {rmse:.2f} seconds\")\n",
    "logger.info(f\"R² Score:                  {r2:.4f}\")\n",
    "\n",
    "champion_mae = float(getattr(config, 'CHAMPION_MAE', 43.18))\n",
    "logger.info(f\"VS Context RF ({champion_mae:.2f}s):  {champion_mae - mae:+.2f}s difference\")\n",
    "\n",
    "# Diagnostics\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "plot_n = min(5000, len(y_pred))\n",
    "plot_indices = np.random.choice(len(y_pred), size=plot_n, replace=False)\n",
    "y_pred_sub = y_pred[plot_indices]\n",
    "y_true_sub = y_true[plot_indices]\n",
    "residuals = y_true_sub - y_pred_sub\n",
    "\n",
    "axes[0].scatter(y_true_sub, y_pred_sub, alpha=0.3, s=10, color='blue')\n",
    "axes[0].plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'r--', lw=2, label='Perfect Fit')\n",
    "axes[0].set_title(f\"GNN Model V3: Predicted vs Actual\\nMAE: {mae:.2f}s | R²: {r2:.2f}\")\n",
    "axes[0].set_xlabel('Actual Delay (s)')\n",
    "axes[0].set_ylabel('Predicted Delay (s)')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].scatter(y_pred_sub, residuals, alpha=0.3, s=10, color='purple')\n",
    "axes[1].axhline(0, color='red', linestyle='--', lw=2)\n",
    "axes[1].set_title('Residuals vs Predictions')\n",
    "axes[1].set_xlabel('Predicted Delay (s)')\n",
    "axes[1].set_ylabel('Error (s)')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "sns.histplot(residuals, bins=50, kde=True, ax=axes[2], color='green')\n",
    "axes[2].axvline(0, color='red', linestyle='--', lw=2)\n",
    "axes[2].set_title('Error Distribution')\n",
    "axes[2].set_xlabel('Error (s)')\n",
    "\n",
    "fig.tight_layout()\n",
    "plot_path = os.path.join(plots_dir, 'gnn_model_v3_diagnostics.png')\n",
    "fig.savefig(plot_path, dpi=150)\n",
    "plt.close(fig)\n",
    "logger.info(f\"Saved diagnostic plots to: {plot_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
